{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQl54-lLcnQX"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yed3qxWcw1K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchmetrics import Precision, Recall\n",
        "from pytorch_unet import UNet\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if cuda_available:\n",
        "    # Get the name of the GPU\n",
        "    gpu_name = torch.cuda.get_device_name(0)  # Assumes you have at least one GPU\n",
        "else:\n",
        "    gpu_name = \"CUDA not available. Running on CPU.\"\n",
        "\n",
        "# Print the results\n",
        "print(f\"CUDA Available: {cuda_available}\")\n",
        "print(f\"GPU Name: {gpu_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBUUCkutcw8K"
      },
      "outputs": [],
      "source": [
        "tiff_directory = 'D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_training\\\\kmms_training\\\\images'\n",
        "png_directory = 'D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_training\\\\kmms_training\\\\images_png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNNGBV9hcw_K"
      },
      "outputs": [],
      "source": [
        "tiff_directory_2 = 'D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_test\\\\kmms_test\\\\images'\n",
        "png_directory_2 = 'D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_test\\\\kmms_test\\\\images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KctaJaVJcxCb"
      },
      "outputs": [],
      "source": [
        "os.makedirs(png_directory_2, exist_ok=True)\n",
        "os.makedirs(png_directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSxaNI8-cxFK"
      },
      "outputs": [],
      "source": [
        "h = 256\n",
        "w = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dh4iCzPcxH7"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, masks, transform=None):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.images[idx], cv2.IMREAD_COLOR)\n",
        "        mask = cv2.imread(self.masks[idx], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        image = cv2.resize(image, (w, h))\n",
        "        mask = cv2.resize(mask, (w, h))\n",
        "\n",
        "        image = image / 255.0\n",
        "        mask = mask / 255.0\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Zr1oI1dG2V"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA6eVDSMdG5I"
      },
      "outputs": [],
      "source": [
        "def load_data(train_path, test_path):\n",
        "    train_images = sorted(glob(os.path.join(train_path, \"images\", \"*.png\")))\n",
        "    train_masks = sorted(glob(os.path.join(train_path, \"masks\", \"*.png\")))\n",
        "\n",
        "    test_images = sorted(glob(os.path.join(test_path, \"images\", \"*.png\")))\n",
        "    test_masks = sorted(glob(os.path.join(test_path, \"masks\", \"*.png\")))\n",
        "\n",
        "    return (train_images, train_masks), (test_images, test_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmusUg3JdG70"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, valid_loader, criterion, optimizer, num_epochs, model_path):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_val_loss = 0.0\n",
        "        for images, masks in train_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            outputs = outputs.squeeze(1)\n",
        "            masks = masks.squeeze(3)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        average_loss = total_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, masks in valid_loader:\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                outputs = outputs.squeeze(1)\n",
        "                masks = masks.squeeze(3)\n",
        "                val_loss = criterion(outputs, masks)\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "            average_val_loss = total_val_loss / len(valid_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.6f}, Val Loss: {average_val_loss:.3f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLLAbSRjdG-T"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = self.conv_block(x)\n",
        "        pooled = self.pool(skip)\n",
        "        return skip, pooled\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, skip_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
        "        self.skip_channels = skip_channels\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.upconv(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv_block(x)\n",
        "        return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.encoder1 = EncoderBlock(in_channels, 64)\n",
        "        self.encoder2 = EncoderBlock(64, 128)\n",
        "        self.encoder3 = EncoderBlock(128, 256)\n",
        "        self.encoder4 = EncoderBlock(256, 512)\n",
        "\n",
        "        self.bottleneck = ConvBlock(512, 1024)\n",
        "\n",
        "        self.decoder1 = DecoderBlock(1024, 512, 512)\n",
        "        self.decoder2 = DecoderBlock(512, 256, 256)\n",
        "        self.decoder3 = DecoderBlock(256, 128, 128)\n",
        "        self.decoder4 = DecoderBlock(128, 64, 64)\n",
        "\n",
        "        self.output_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip1, x = self.encoder1(x)\n",
        "        skip2, x = self.encoder2(x)\n",
        "        skip3, x = self.encoder3(x)\n",
        "        skip4, x = self.encoder4(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        x = self.decoder1(x, skip4)\n",
        "        x = self.decoder2(x, skip3)\n",
        "        x = self.decoder3(x, skip2)\n",
        "        x = self.decoder4(x, skip1)\n",
        "\n",
        "        x = self.output_conv(x)\n",
        "        # print(\"shape of x from model:\",x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-xb70PBdHBE"
      },
      "outputs": [],
      "source": [
        "def load_data(images_folder, masks_folder):\n",
        "    train_images = sorted(glob(os.path.join(images_folder, \"*.png\")))\n",
        "    train_masks = sorted(glob(os.path.join(masks_folder, \"*.png\")))\n",
        "\n",
        "    return train_images, train_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOGViv46dHDW",
        "outputId": "eb9474db-3ece-4e73-93bc-8f984a17dad3"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # create_dir(\"files\")\n",
        "\n",
        "    batch_size = 16\n",
        "    learning_rate = 1e-4\n",
        "    num_epochs = 50\n",
        "    model_path = \"D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\model.pth\"\n",
        "\n",
        "    train_img_path = \"D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_training\\\\kmms_training\\\\images_png\"\n",
        "    test_img_path = \"D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_test\\\\kmms_test\\\\images\"\n",
        "    train_mask_path = \"D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_training\\\\kmms_training\\\\masks\"\n",
        "    test_mask_path = \"D:\\\\Code\\\\PyTorch_Segmentation\\\\ImageSegmentation\\\\kmms_test\\\\kmms_test\\\\masks\"\n",
        "\n",
        "    train_images, train_masks = load_data(train_img_path, train_mask_path)\n",
        "    test_images, test_masks = load_data(test_img_path, test_mask_path)\n",
        "    #train_images, train_masks = shuffle(train_images, train_masks)\n",
        "\n",
        "    # print(f\"Train: {len(train_images)} - {len(train_masks)}\")\n",
        "    # print(f\"Test: {len(test_images)} - {len(test_masks)}\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.float())])\n",
        "\n",
        "\n",
        "    train_dataset = CustomDataset(train_images, train_masks, transform=transform)\n",
        "    test_dataset = CustomDataset(test_images, test_masks, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    input_size = (h,w,3)\n",
        "    model = UNet(in_channels=input_size[2], out_channels=1)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train(model, train_loader, test_loader, criterion, optimizer, num_epochs, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wH9Fv9tpGNE"
      },
      "outputs": [],
      "source": [
        "def tensor_to_numpy(tensor):\n",
        "    \"\"\"Convert a PyTorch tensor to a NumPy array.\"\"\"\n",
        "    return tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rwr3Nd5bAVZw",
        "outputId": "819d4b84-37d0-4c01-de08-f6bcfb1d430f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# IOU score list -> it will get updated after each comparision\n",
        "iou_scores = []\n",
        "\n",
        "# Assuming threshold value of 0.5, adjust as needed\n",
        "threshold = 0.1\n",
        "# Iterate over the test loader and make predictions\n",
        "for images, masks in test_loader:\n",
        "    with torch.no_grad():\n",
        "        # Forward pass\n",
        "        predictions = model(images)\n",
        "    predictions = predictions.squeeze(1)\n",
        "    masks = masks.squeeze(3)\n",
        "    images = images.squeeze(1)\n",
        "    # Convert PyTorch tensor to NumPy array for plotting\n",
        "    images_np = [np.array(tensor_to_numpy(img)) for img in images]\n",
        "    predictions_np = [np.array(tensor_to_numpy(pred)) for pred in predictions]\n",
        "    masks_np = [np.array(tensor_to_numpy(mask)) for mask in masks]\n",
        "\n",
        "\n",
        "\n",
        "    # Plot the original images, segmented results, and ground truth masks\n",
        "    for i in range(len(images)):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        # Plot original image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(images_np[i].T)\n",
        "        plt.title(\"Original Image\")\n",
        "\n",
        "        # Plot segmented result\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(predictions_np[i], cmap='gray')\n",
        "        plt.title(\"Segmented Result\")\n",
        "\n",
        "        # Plot ground truth mask\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(masks_np[i], cmap='gray')\n",
        "        plt.title(\"Ground Truth Mask\")\n",
        "\n",
        "        plt.show()  # Display the figure\n",
        "\n",
        "        # Close the current figure to avoid the warning\n",
        "        plt.close()\n",
        "\n",
        "        for i in range(len(predictions)):\n",
        "            # Convert tensors to numpy arrays\n",
        "            pred_flat = (predictions[i] > threshold).view(-1).cpu().numpy()\n",
        "            mask_flat = (masks[i] > threshold).view(-1).cpu().numpy()\n",
        "\n",
        "            # Calculate IoU\n",
        "            iou = jaccard_score(mask_flat, pred_flat)\n",
        "            iou_scores.append(iou)\n",
        "\n",
        "print(iou_scores)\n",
        "# Average IoU over all samples\n",
        "average_iou = np.mean(iou_scores)\n",
        "\n",
        "print(f'Average IoU: {average_iou}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
